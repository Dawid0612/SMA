import os
import streamlit as st
from dotenv import load_dotenv
load_dotenv(dotenv_path=".env")
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
import datetime
import json
from fpdf import FPDF

PASSWORD = "StrategiaMA2025"
st.set_page_config(page_title="Strategia MA â€“ Pro", layout="wide")
st.title("ğŸ“Š Strategia MA â€“ Bot Strategiczny Pro")

password = st.text_input("ğŸ”’ Wpisz hasÅ‚o dostÄ™pu:", type="password")
if password != PASSWORD:
    st.stop()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
llm = ChatOpenAI(temperature=0.3, openai_api_key=OPENAI_API_KEY)

os.makedirs("docs", exist_ok=True)
os.makedirs("history", exist_ok=True)

def load_documents():
    documents = []
    for filename in os.listdir("docs"):
        filepath = os.path.join("docs", filename)
        if filename.endswith(".pdf"):
            loader = PyPDFLoader(filepath)
        elif filename.endswith(".docx"):
            loader = Docx2txtLoader(filepath)
        elif filename.endswith(".txt"):
            loader = TextLoader(filepath)
        else:
            continue
        documents.extend(loader.load())
    return documents

def save_chat_history(history):
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"history/chat_{now}.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2)
    return filename

def export_chat_to_pdf(chat):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    for entry in chat:
        pdf.multi_cell(0, 10, f"Ty: {entry['question']}")
        pdf.multi_cell(0, 10, f"Strategia MA: {entry['answer']}")
        pdf.ln()
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    pdf_path = f"history/chat_{now}.pdf"
    pdf.output(pdf_path)
    return pdf_path

def list_saved_chats():
    return [f for f in os.listdir("history") if f.endswith(".json")]

# ğŸ”½ Wgrywanie plikÃ³w
uploaded_files = st.file_uploader("ğŸ“ Wgraj dokumenty (PDF, DOCX, TXT):", type=["pdf", "docx", "txt"], accept_multiple_files=True)
if uploaded_files:
    for file in uploaded_files:
        with open(os.path.join("docs", file.name), "wb") as f:
            f.write(file.getbuffer())
    st.success("âœ… Pliki zostaÅ‚y zapisane!")

# ğŸ“‚ Lista dokumentÃ³w
st.markdown("## ğŸ“‚ Wgrane dokumenty")
doc_files = os.listdir("docs")
if not doc_files:
    st.info("Brak dokumentÃ³w. Wgraj coÅ› powyÅ¼ej.")
else:
    for file in doc_files:
        st.markdown(f"âœ… {file}")

# ğŸ“š Przetwarzanie dokumentÃ³w
with st.spinner("ğŸ“š Przetwarzanie dokumentÃ³w..."):
    documents = load_documents()
    st.info(f"ğŸ“„ Znaleziono {len(documents)} dokumentÃ³w.")
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = splitter.split_documents(documents)
    st.info(f"ğŸ” Podzielono na {len(split_docs)} fragmentÃ³w.")

    chain = None
    if not split_docs:
        st.warning("â— Bot nie ma danych do analizy â€“ odpowiada tylko ogÃ³lnie
